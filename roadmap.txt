-- To Do?
* Memory for Generator-Evaluator + Human
* tokens usage
* get resume chunks related to each criteria component for prompt injection

-- session 20250916
* weights 
* relevant experience parameter from candidates
* validation layer: Hiring manager agent? How to validate?
* personalised technical assessment (?)
* project description: which consultant can I send? Wishes? Availability? Training?
* Modify the consultant profile to the send for a company
* add the name instead of id 

-- other branch of this
* comunication skills based on videos

-- 20250922 tasks list:
* add conversation memory using messages (DONE)
* add weights of components to the prompt (DONE)
* compute the total score based on the weights (DONE)
* filter the best overall candidates (DONE)
* generate interview questions for the best candidates (DONE)
* generate a structured output for the candidates experience as JSON file (DONE)

-- 20250923 tasks list:
* remove the fields with many na values (Instead, do not count them on the criteria average)
* find a way to redistribute the weights proportional of the removed columns (DONE)
* do not count null values for the average (DONE)
* explanation for each score and criteria component
* based on the skills of the candidate, what technical questions can assess if the candidate really knows what they mentioned
* behaviour in the workplace
* non-tehcnical questions that validate if the candidate knows that he is talking about
* evaluate what is the score for candidates like Nikki and Eric Zang compared to top candidates

-- 20250930 tasks list:
* evalute the candidates relative to others
* provide post scoring explanations
* add the name of the candidate to the csv file

-- 20251007 What to do today?
* change the IDs from the table (DONE)
* added name to the csv file (DONE)
* add explanations of the scores (DONE)
* integrate the hybrid approach:
1. generate a reduced list of components for the evaluation criteria
2. tournament selection for the complete pool of candidates
3. scores only for the best candidates
4. experience only for the top candidates
5. interview questions based on the experience only
* export the rationale of the rounds for the tournament (DONE)

-- 20251014 improvements upon the current workflow:
* teams of specialist in each criteria component for the candidate tournament (Not priority)
* add a supervisor agent for the full workflow (Not priority)
* reduce to 10% of the total candidtes (needs to change in worflow)
* force the names or ids on the explantions per round (include that name medatada con the prompt)


* what should we look for on every answer? - Done
* strenghts and weakness summary
* refine technical questions - DONE
* results from different models

What to do 20250211?
* modifiy the tournament selection prompt to adjust the number of candidates (DONE)
* before running the tournament, show the user how many candidates (DONE)
will be at the end of every round, and allow to set the rounds manually
* strenghts and weaknesses of each of the top candidates
* run the workflow with different models
* prepare the presentation

-- standard criteria
Data Analytics,Business Transformation,Information Technology,Analytical Methodologies,Data Literacy,Understanding of ETL Processes,Problem Solving,Client Engagement,Collaboration,Team-oriented,Eager to Learn,Adaptabilitymake questions relevant to the level of experience of the role
make adjustmen on experience questions as well
